{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910d6335",
   "metadata": {},
   "source": [
    "## torch_to_trt.ipynb 를 통해 결과의 아웃풋의 크기도 다르고 성능도 제대로 나오지않아서 구글링한 결과 torch2trt_dynamic이라는 것을 알게 됨\n",
    "## 이것은 CRAFT와 같이 정해진 인풋 이미지 크기의 영향을 받지 않는 모델을 위해서 torch2trt를 커스텀한 것임\n",
    "\n",
    "#### https://github.com/grimoire/torch2trt_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b9504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['NVIDIA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20608f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321ea8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from text_detection import craft_utils\n",
    "from text_detection import imgproc\n",
    "import text_detection.file_utils\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "from text_detection.craft import CRAFT\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")\n",
    "\n",
    "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly,refine_net=None):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, args.canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=args.mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    \n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "    \n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
    "\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "    \n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "    \n",
    "    if args.show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, ret_score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self,cuda=False, trained_model='weights/craft_mlt_25k.pth', text_threshold=0.7, low_text=0.4, link_threshold=0.4, canvas_size =1280, mag_ratio=1.5, poly=False, show_time=False,test_folder='/data/',refine=False, refiner_model='weights/craft_refiner_CTW1500.pth'):\n",
    "        self.cuda = cuda\n",
    "        self.trained_model = trained_model = trained_model\n",
    "        self.text_threshold = text_threshold\n",
    "        self.low_text = low_text\n",
    "        self.link_threshold = link_threshold\n",
    "        self.canvas_size = canvas_size\n",
    "        self.mag_ratio = mag_ratio\n",
    "        self.poly = poly\n",
    "        self.show_time = show_time\n",
    "        self.test_folder = test_folder\n",
    "        self.refine = refine\n",
    "        self.refiner_model = refiner_model\n",
    "        \n",
    "        \n",
    "def img_show(img, size =(15,15)):\n",
    "    plt.rcParams[\"figure.figsize\"] = size\n",
    "    imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad78e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "    \n",
    "args = Args(test_folder='./',text_threshold=0.8,link_threshold=0.4,canvas_size=1200,refine=False,poly=False,cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a79219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (weights/craft_mlt_25k.pth)\n",
      "cuda\n",
      "torch.cuda.memory_allocated: 81.041504MB\n"
     ]
    }
   ],
   "source": [
    "regist_img_num = 0\n",
    "# test_img_num = 1\n",
    "\n",
    "# load net\n",
    "net = CRAFT()     # initialize\n",
    "\n",
    "print('Loading weights from checkpoint (' + args.trained_model + ')')\n",
    "# device=torch.device('cuda')\n",
    "\n",
    "net.load_state_dict(copyStateDict(torch.load(args.trained_model,map_location=\"cuda\")))\n",
    "print(device)\n",
    "\n",
    "net = net.to(device)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "net.eval()\n",
    "\n",
    "craft_memory = torch.cuda.memory_allocated()/1024/1024\n",
    "\n",
    "print(\"torch.cuda.memory_allocated: %fMB\"%(craft_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca364bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_memory: 81.04150390625\n",
      "Loading weights of refiner from checkpoint (weights/craft_refiner_CTW1500.pth)\n",
      "torch.cuda.memory_allocated: 81.041504MB\n",
      "cuda\n",
      "after_memory: 82.80859375\n",
      "torch.cuda.memory_allocated: 1.767090MB\n"
     ]
    }
   ],
   "source": [
    "print(\"current_memory:\", craft_memory)\n",
    "\n",
    "# LinkRefiner\n",
    "from refinenet import RefineNet\n",
    "refine_net = RefineNet()\n",
    "print('Loading weights of refiner from checkpoint (' + args.refiner_model + ')')\n",
    "\n",
    "print(\"torch.cuda.memory_allocated: %fMB\"%(torch.cuda.memory_allocated()/1024/1024))\n",
    "if args.cuda:\n",
    "    refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model,map_location=\"cuda\")))\n",
    "#     refine_net.load_state_dict(torch.load(args.refiner_model))\n",
    "    refine_net = refine_net.to(device)\n",
    "    print(device)\n",
    "#     refine_net = torch.nn.DataParallel(refine_net)\n",
    "else:\n",
    "    refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model, map_location='cpu')))\n",
    "\n",
    "refine_net.eval()\n",
    "args.poly = True\n",
    "\n",
    "refine_memory = torch.cuda.memory_allocated()/1024/1024\n",
    "print(\"after_memory:\", refine_memory)\n",
    "print(\"torch.cuda.memory_allocated: %fMB\"%(refine_memory - craft_memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d95132",
   "metadata": {},
   "source": [
    "### 아래에서 torch2trt_dynamic 함수를 통해 모델을 로드 \n",
    "\n",
    "### unknown interpolate type, use linear instead 이라는 오류를 직면 \n",
    "\n",
    "### 이를 해결하기 위해 plugin을 다른 것으로 해보는 시도를 했지만 잘 안됨 \n",
    "\n",
    "### 그런 와중 unknown interpolate type이 혹시 tensorRT docker 컨테이너의 버전이 낮아서 특정 레이어를 지원하지 않는 것이라는 것을 알게됨. \n",
    "\n",
    "### 실제로 github에서도 tensorRT 7.x버전 이상에서 잘 작동된다고 하여 해당 버전에 맞게 컨테이너를 다시 띄워주었다.\n",
    "\n",
    "### 또한 torch2onnx, onnx2trt의 단계를 거치지 않고 torch2trt 모듈로만 구현하기에는 한계(특정레이어 지원X, github star수 낮음 등)가 있다고 판단되어 \n",
    "\n",
    "### torch2onnx, onnx2trt의 두 단계로 변환을 시도하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700a2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown interpolate type, use linear instead.\n",
      "unknown interpolate type, use linear instead.\n",
      "unknown interpolate type, use linear instead.\n"
     ]
    }
   ],
   "source": [
    "from torch2trt_dynamic import torch2trt_dynamic\n",
    "\n",
    "input_tensor = torch.randn((1, 3, 768, 768), requires_grad=False)\n",
    "input_tensor=input_tensor.cuda()\n",
    "input_tensor=input_tensor.to(device=device)\n",
    "\n",
    "opt_shape_param = [\n",
    "    [\n",
    "        [1,3,256,256],   # min\n",
    "        [1,3,700,700],   # opt\n",
    "        [1,3,1200,1200]    # max\n",
    "    ]\n",
    "]\n",
    "\n",
    "model_trt = torch2trt_dynamic(net, [input_tensor], fp16_mode=True, opt_shape_param=opt_shape_param)\n",
    "\n",
    "output_path = './weights/'\n",
    "output_detec = os.path.join(output_path, \"detec_rt.engine\")\n",
    "# with open(output_detec, \"wb\") as f:\n",
    "#         f.write(model_trt.engine.serialize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6d8ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorrt' has no attribute 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc423eeadff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_trt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# check the output against PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/torch2trt_dynamic/torch2trt_dynamic/torch2trt_dynamic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_binding_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_dtype_from_trt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_binding_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_binding_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/torch2trt_dynamic/torch2trt_dynamic/torch2trt_dynamic.py\u001b[0m in \u001b[0;36mtorch_dtype_from_trt\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_dtype_from_trt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorrt' has no attribute 'bool'"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,3,256,256).cuda()\n",
    "with torch.no_grad():\n",
    "    y = net(x)\n",
    "    y_trt = model_trt(x)\n",
    "\n",
    "# check the output against PyTorch\n",
    "print(torch.max(torch.abs(y - y_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2302591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
