{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d067213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'_BASE_': CfgNode({}), 'INFERENCE': CfgNode({'TEXT_THRESHOLD': 0.7, 'LINK_THRESHOLD': 0.4, 'LOW_TEXT_SCORE': 0.4, 'OX_DO_CONSTANT_FOLDING': True, 'OX_EXPORT_PARAMS': True, 'OX_OPSET': 11, 'OX_VERBOSE': False, 'TRT_DYNAMIC': True, 'TRT_MIN_SHAPE': (1, 3, 256, 256), 'TRT_OPT_SHAPE': (1, 3, 700, 700), 'TRT_MAX_SHAPE': (1, 3, 1200, 1200), 'TRT_AMP': True, 'TRT_WORKSPACE': 5})})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "import argparse\n",
    "import onnx_graphsurgeon as gs\n",
    "\n",
    "from utils import experiment_loader, initial_logger, copyStateDict, get_cfg_defaults\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from craft import CRAFT\n",
    "\n",
    "cfg_detec = get_cfg_defaults()\n",
    "cfg_detec\n",
    "# weight_path = '../weights'\n",
    "# model_path, model_config = experiment_loader(model_format='pth', data_path=weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39bf08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "_____________________________________________________________________________\n",
    "\n",
    "This file contain code for converting trained model into ONNX format\n",
    "Refer from TensorRT example: tensorrt/bin/python/onnx_packnet\n",
    "_____________________________________________________________________________\n",
    "\"\"\"\n",
    "# from icecream import ic\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "import argparse\n",
    "import onnx_graphsurgeon as gs\n",
    "\n",
    "from utils import experiment_loader, initial_logger, copyStateDict, get_cfg_defaults\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from craft import CRAFT\n",
    "\n",
    "logger = initial_logger()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def build_onnx(weight_path):\n",
    "    \"\"\"Load the network and export it to ONNX\n",
    "    \"\"\"\n",
    "    logger.info(\"Converting detec pth to onnx...\")\n",
    "\n",
    "    model_path, model_config = experiment_loader(model_format='pth', data_path=weight_path)\n",
    "    \n",
    "    # Load config come with trained model\n",
    "    cfg_detec = get_cfg_defaults()\n",
    "    cfg_detec.merge_from_file(model_config)\n",
    "    \n",
    "    # Set output path for onnx files\n",
    "    output_path = Path('../weights')\n",
    "    \n",
    "    # Set name for onnx files\n",
    "    output_detec = os.path.join(output_path, \"detec_onnx.onnx\")\n",
    "    \n",
    "    # Dummy input data for models\n",
    "    input_tensor_detec = torch.randn((1, 3, 768, 768), requires_grad=False)\n",
    "    input_tensor_detec=input_tensor_detec.cuda()\n",
    "    input_tensor_detec=input_tensor_detec.to(device=device)\n",
    "\n",
    "    # Load net\n",
    "    net = CRAFT()\n",
    "    net.load_state_dict(copyStateDict(torch.load(model_path)))\n",
    "    net = net.cuda()\n",
    "    net.eval()\n",
    "\n",
    "    # Convert the model into ONNX\n",
    "    torch.onnx.export(net, input_tensor_detec, output_detec,\n",
    "                      verbose=cfg_detec.INFERENCE.OX_VERBOSE, opset_version=cfg_detec.INFERENCE.OX_OPSET,\n",
    "                      do_constant_folding=cfg_detec.INFERENCE.OX_DO_CONSTANT_FOLDING,\n",
    "                      export_params=cfg_detec.INFERENCE.OX_EXPORT_PARAMS,\n",
    "                      input_names=[\"input\"],\n",
    "                      output_names=[\"output\", \"output1\"],\n",
    "                      dynamic_axes={\"input\": {0: \"batch\", 2: \"height\", 3: \"width\"}})\n",
    "\n",
    "    logger.info(\"Convert detec pth to ONNX sucess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e5897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description=\"Exports model to ONNX, and post-processes it to insert TensorRT plugins\")\n",
    "# parser.add_argument(\"--weight\", required=False, help=\"Path to input model folder\", default='/workspace/DBP/NAS저장공간/hengbee/ONNX-TensorRT-Inference-CRAFT-pytorch/weights')\n",
    "# args=parser.parse_args()\n",
    "# print(args.weight)\n",
    "\n",
    "weight_path = '../weights'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d81e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_onnx(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f19676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_memory: 0.0\n",
      "load time: 0.28368711471557617\n",
      "onnx_load_mem: 0.000000MB\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import time\n",
    "\n",
    "onnx_load_befo_mem = torch.cuda.memory_allocated()/1024/1024\n",
    "print(\"current_memory:\", onnx_load_befo_mem)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "output_path = Path('../weights')\n",
    "# Set name for onnx files\n",
    "output_detec = os.path.join(output_path, \"detec_onnx.onnx\")\n",
    "# Load the ONNX model\n",
    "model = onnx.load(output_detec)\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "print(f'load time: {time.time()-t2}')\n",
    "\n",
    "onnx_load_mem = torch.cuda.memory_allocated()/1024/1024\n",
    "\n",
    "print(\"onnx_load_mem: %fMB\"%(onnx_load_mem-onnx_load_befo_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68e0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_memory: 0.0\n",
      "Test image : ../IMG_8178.jpg\n",
      "torch.Size([1, 3, 4032, 3024])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-576f2185cf04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m outputs = ort_session.run(\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import imgproc\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "\n",
    "onnx_infer_befo_mem = torch.cuda.memory_allocated()/1024/1024\n",
    "print(\"current_memory:\", onnx_infer_befo_mem)\n",
    "\n",
    "t = time.time()\n",
    "image_path = '../IMG_8178.jpg'\n",
    "print(\"Test image :\", image_path)\n",
    "\n",
    "image = imgproc.loadImage(image_path)\n",
    "ort_session = ort.InferenceSession(output_detec)\n",
    "img_resized = imgproc.normalizeMeanVariance(image)\n",
    "img_resized = torch.from_numpy(img_resized).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "img_resized = Variable(img_resized.unsqueeze(0))\n",
    "img_resized.cuda()\n",
    "print(img_resized.shape)\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\"input\": np.array(img_resized).astype(np.float32)},\n",
    ")\n",
    "print(outputs[0])\n",
    "print(f'load time: {time.time()-t}')\n",
    "onnx_infer_mem = torch.cuda.memory_allocated()/1024/1024\n",
    "\n",
    "print(\"onnx_load_mem: %fMB\"%(onnx_infer_mem-onnx_infer_befo_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63226d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text = outputs[0][0,:,:,0]\n",
    "score_link = outputs[0][0,:,:,1]\n",
    "score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ae010",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def img_show(img, size =(15,15)):\n",
    "    plt.rcParams[\"figure.figsize\"] = size\n",
    "    imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(score_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ba377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
