{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b7bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ['NVIDIA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fc5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "_____________________________________________________________________________\n",
    "\n",
    "This file contains code for convert from onnx to tensorRT engine\n",
    "_____________________________________________________________________________\n",
    "\"\"\"\n",
    "import sys\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import onnx\n",
    "import argparse\n",
    "\n",
    "from utils import experiment_loader, initial_logger, copyStateDict, get_cfg_defaults\n",
    "\n",
    "from config import _C\n",
    "logger = initial_logger()\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "a=(int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "\n",
    "def build_detec_engine(onnx_path, using_half, engine_file, dynamic_input=True, workspace_size=5, \n",
    "                min_shape=(1,3,256,256), opt_shape=(1,3,700,700), max_shape=(1,3,1200,1200)):\n",
    "    trt.init_libnvinfer_plugins(None, '')\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network(EXPLICIT_BATCH) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        builder.max_batch_size = 1 # always 1 for explicit batch\n",
    "        config = builder.create_builder_config()\n",
    "        config.max_workspace_size = GiB(int(workspace_size))\n",
    "        if using_half:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "        # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "        with open(onnx_path, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                print ('ERROR: Failed to parse the ONNX file.')\n",
    "                for error in range(parser.num_errors):\n",
    "                    print (parser.get_error(error))\n",
    "                return None\n",
    "        \n",
    "        if dynamic_input:\n",
    "            profile = builder.create_optimization_profile();\n",
    "            profile.set_shape(\"input\", min_shape, opt_shape, max_shape) \n",
    "            config.add_optimization_profile(profile)\n",
    "   \n",
    "        return builder.build_engine(network, config) \n",
    "\n",
    "\n",
    "# Sample run cmd: for ex, engine optimze for gpu:0\n",
    "# CUDA_VISIBLE_DEVICES=0 python onnx2trt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f779d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21mINFO - Converting detec ONNX to TensorRT engine... (<ipython-input-3-2bb9bec3d9e3>:7)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set dynamic input size in associate function, find: profile.set_shape\n",
    "# parser = argparse.ArgumentParser(description=\"Convert ONNX model into TensorRT\")\n",
    "# parser.add_argument(\"--weight\", required=False, help=\"Path to input model folder\", default='../weights')\n",
    "\n",
    "# args=parser.parse_args()\n",
    "weight_path = '../weights'\n",
    "logger.info(\"Converting detec ONNX to TensorRT engine...\")\n",
    "\n",
    "model_path, model_config = experiment_loader(model_format='onnx', data_path=weight_path)\n",
    "\n",
    "# Process names\n",
    "# Set output path for onnx files\n",
    "output_path = Path('../weights')\n",
    "\n",
    "# Set name for onnx files\n",
    "# output_detec = os.path.join(output_path, \"detec_trt.engine\")\n",
    "output_detec = os.path.join(output_path, \"detec_trt2.engine\")\n",
    "\n",
    "cfg_detec = get_cfg_defaults()\n",
    "cfg_detec.merge_from_file(model_config)\n",
    "\n",
    "# # start build\n",
    "# detec_engine=build_detec_engine(model_path, cfg_detec.INFERENCE.TRT_AMP, output_detec, dynamic_input=cfg_detec.INFERENCE.TRT_DYNAMIC, \n",
    "#             workspace_size=cfg_detec.INFERENCE.TRT_WORKSPACE, min_shape=cfg_detec.INFERENCE.TRT_MIN_SHAPE, \n",
    "#             opt_shape=cfg_detec.INFERENCE.TRT_OPT_SHAPE, max_shape=cfg_detec.INFERENCE.TRT_MAX_SHAPE)\n",
    "\n",
    "detec_engine=build_detec_engine(model_path, cfg_detec.INFERENCE.TRT_AMP, output_detec, dynamic_input=False, \n",
    "            workspace_size=cfg_detec.INFERENCE.TRT_WORKSPACE, min_shape=cfg_detec.INFERENCE.TRT_MIN_SHAPE, \n",
    "            opt_shape=cfg_detec.INFERENCE.TRT_OPT_SHAPE, max_shape=cfg_detec.INFERENCE.TRT_MAX_SHAPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6af3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_detec.merge_from_file(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340097d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'_BASE_': CfgNode({}), 'INFERENCE': CfgNode({'TEXT_THRESHOLD': 0.7, 'LINK_THRESHOLD': 0.4, 'LOW_TEXT_SCORE': 0.4, 'OX_DO_CONSTANT_FOLDING': True, 'OX_EXPORT_PARAMS': True, 'OX_OPSET': 11, 'OX_VERBOSE': False, 'TRT_DYNAMIC': True, 'TRT_MIN_SHAPE': (1, 3, 256, 256), 'TRT_OPT_SHAPE': (1, 3, 700, 700), 'TRT_MAX_SHAPE': (1, 3, 1200, 1200), 'TRT_AMP': True, 'TRT_WORKSPACE': 5})})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_detec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2de7468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'TEXT_THRESHOLD': 0.7, 'LINK_THRESHOLD': 0.4, 'LOW_TEXT_SCORE': 0.4, 'OX_DO_CONSTANT_FOLDING': True, 'OX_EXPORT_PARAMS': True, 'OX_OPSET': 11, 'OX_VERBOSE': False, 'TRT_DYNAMIC': True, 'TRT_MIN_SHAPE': (1, 3, 256, 256), 'TRT_OPT_SHAPE': (1, 3, 700, 700), 'TRT_MAX_SHAPE': (1, 3, 1200, 1200), 'TRT_AMP': True, 'TRT_WORKSPACE': 5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_detec.INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551d5280",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'serialize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-be665feb1f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetec_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'serialize'"
     ]
    }
   ],
   "source": [
    "detec_engine.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473fc77c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'serialize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8429230495e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_detec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetec_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Build RT engine of detec successfully! Ready to infer.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'serialize'"
     ]
    }
   ],
   "source": [
    "with open(output_detec, \"wb\") as f:\n",
    "    f.write(detec_engine.serialize())\n",
    "    \n",
    "logger.info('Build RT engine of detec successfully! Ready to infer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e24cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
