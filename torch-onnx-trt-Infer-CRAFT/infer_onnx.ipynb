{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "_____________________________________________________________________________\n",
    "\n",
    "This file contains main inference pipeline to Triton\n",
    "_____________________________________________________________________________\n",
    "\"\"\"\n",
    "from icecream import ic\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import craft_utils\n",
    "import imgproc\n",
    "import file_utils\n",
    "import json\n",
    "import zipfile\n",
    "import onnxruntime\n",
    "\n",
    "from collections import OrderedDict\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Triton inference pipeline for CRAFT Text Detection')\n",
    "# parser.add_argument('--text_threshold', default=0.7, type=float, help='text confidence threshold')\n",
    "# parser.add_argument('--low_text', default=0.4, type=float, help='text low-bound score')\n",
    "# parser.add_argument('--link_threshold', default=0.4, type=float, help='link confidence threshold')\n",
    "# parser.add_argument('--cuda', default=True, type=str2bool, help='Use cuda for inference')\n",
    "# parser.add_argument('--canvas_size', default=1100, type=int, help='image size for inference')\n",
    "# parser.add_argument('--mag_ratio', default=1.5, type=float, help='image magnification ratio')\n",
    "# parser.add_argument('--poly', default=False, action='store_true', help='enable polygon type')\n",
    "# parser.add_argument('--show_time', default=False, action='store_true', help='show processing time')\n",
    "# parser.add_argument('--test_folder', default='images/', type=str, help='folder path to input images')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\"\"\" For test images in a folder \"\"\"\n",
    "image_list, _, _ = file_utils.get_files(args.test_folder)\n",
    "\n",
    "result_folder = './result/'\n",
    "if not os.path.isdir(result_folder):\n",
    "    os.mkdir(result_folder)\n",
    "\n",
    "def test_net(args, image, text_threshold, link_threshold, low_text, cuda, poly):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # load onnx file\n",
    "    data_path = Path('./weights')\n",
    "    model_path = str(sorted(data_path.glob('*.onnx'))[0])\n",
    "    ic(str(model_path))\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, args.canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=args.mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    img_resized = imgproc.normalizeMeanVariance(img_resized)\n",
    "    img_resized = torch.from_numpy(img_resized).permute(2, 0, 1)    # [h, w, c] to [c, h, w]    \n",
    "\n",
    "    img_resized = (img_resized.unsqueeze(0))  # [c, h, w] to [b, c, h, w]\n",
    "    img_resized = img_resized.to(device)\n",
    "    ort_session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "    # compute ONNX Runtime output prediction\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_resized)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    y= ort_outs[0]\n",
    "   \n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0]\n",
    "    score_link = y[0,:,:,1]\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "    if args.show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, ret_score_text\n",
    "\n",
    "\n",
    "# Example cmd:\n",
    "# python infer_onnx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c60429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self,cuda=True, trained_model='weights/craft_mlt_25k.pth', text_threshold=0.7, low_text=0.4, link_threshold=0.4, canvas_size =1100, mag_ratio=1.5, poly=False, show_time=False,test_folder='/data/',refine=False, refiner_model='weights/craft_refiner_CTW1500.pth'):\n",
    "        self.cuda = cuda\n",
    "        self.trained_model = trained_model = trained_model\n",
    "        self.text_threshold = text_threshold\n",
    "        self.low_text = low_text\n",
    "        self.link_threshold = link_threshold\n",
    "        self.canvas_size = canvas_size\n",
    "        self.mag_ratio = mag_ratio\n",
    "        self.poly = poly\n",
    "        self.show_time = show_time\n",
    "        self.test_folder = test_folder\n",
    "        self.refine = refine\n",
    "        self.refiner_model = refiner_model\n",
    "        \n",
    "def img_show(img, size =(15,15)):\n",
    "    plt.rcParams[\"figure.figsize\"] = size\n",
    "    imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480462b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "t = time.time()\n",
    "# load data\n",
    "for k, image_path in enumerate(image_list):\n",
    "    print(\"Test image {:d}/{:d}: {:s}\".format(k+1, len(image_list), image_path), end='\\r')\n",
    "    image = imgproc.loadImage(image_path)\n",
    "\n",
    "    bboxes, polys, score_text = test_net(args, image, args.text_threshold, args.link_threshold, args.low_text, args.cuda, args.poly)\n",
    "\n",
    "    # save score text\n",
    "    # filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "    # mask_file = result_folder + \"/res_\" + filename + '_mask_triton.jpg'\n",
    "    # cv2.imwrite(mask_file, score_text)\n",
    "\n",
    "    file_utils.saveResult(image_path, image[:,:,::-1], polys, dirname=result_folder, method='onnx')\n",
    "\n",
    "print(\"elapsed time : {}s\".format(time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
